#!/usr/bin/env python
# -*- coding: utf-8 -*-#
#
#
# Copyright (C) 2015, S3IT, University of Zurich. All rights reserved.
#
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
"""Collect OpenStack usage information, produce a report and send an
email to the project contact email addresses.

"""
__docformat__ = 'reStructuredText'
__author__ = 'Antonio Messina <antonio.s.messina@gmail.com>'

# Metrics http://docs.openstack.org/admin-guide-cloud/content/section_telemetry-compute-meters.html

from collections import defaultdict, namedtuple
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.image import MIMEImage
import argparse
import calendar
import csv
import datetime
import getpass
import logging
import multiprocessing as mp
import operator
import os
import prettytable
import re
import smtplib
import sys
import time
import sqlalchemy as sqla
import sqlalchemy.orm
import sqlalchemy.sql as sql

PLOT_ENABLED=True
try:
    # matplotlib doesn't play nice when X11 is not present.
    # cfr. http://stackoverflow.com/questions/2801882/generating-a-png-with-matplotlib-when-display-is-undefined
    import matplotlib
    matplotlib.use('Agg')

    import pandas as pd
    from matplotlib import pylab as plt
except ImportError as ex:
    PLOT_ENABLED=False

class NovaSummary:
    def __init__(self):
        self.project_id = None
        self.total_vcpus_usage = 0
        self.total_memory_mb_usage = 0
        self.server_usages = []

    def append(self, instance):
        self.server_usages.append(instance)
        duration = (instance['end'] - instance['start']).total_seconds()/60/60
        self.total_vcpus_usage += instance['hours']
        self.total_memory_mb_usage += duration*instance['memory_mb']

# try:
#     import seaborn
# except:
#     # seaborn is used only to make plots nicer.
#     pass

import swiftclient.client as swiftclient

from keystoneclient.auth.identity import v3
from keystoneclient import session
from keystoneclient.v3 import client as keystone_client
try:
    # old package name
    from keystoneclient.openstack.common.apiclient.exceptions import NotFound
except ImportError:
    from keystoneclient.exceptions import NotFound

from novaclient import client as nova_client
from cinderclient import client as cinder_client

respolicy = re.compile('x-account-storage-policy-(?P<policy>.*)-(?P<value>bytes-used|object-count)')

log = logging.getLogger()
log.addHandler(logging.StreamHandler())


### COSTS
cost_base_hpc = 0.002
cost_base_server = 0.001
cost_base_cinder = 50.0/1024/365/24
cost_vhp_cinder = 100.0/1024/365/24
FLAVOR_COSTS = {'{}cpu-{}ram-hpc'.format(i, i*4): i*cost_base_hpc for i in (1,2,4,8,16,32)}
FLAVOR_COSTS.update({'{}cpu-{}ram-server'.format(i, i): i*cost_base_server for i in (1,2,4,8)})

### amazon costs
# c4.large	2	8	3.75	EBS Only	$0.105 per Hour
amazon_cost_base_hpc = 0.05
# t2.micro	1	Variable	1	EBS Only	$0.013 per Hour
amazon_cost_base_server = 0.013

# Amazon EBS Throughput Optimized HDD (st1) volumes
# $0.045 per GB-month of provisioned storage
amazon_cost_base_cinder = 0.045/30/24

### Converion functions
def compute_price_nova(instance):
    # hours is actuall cpu-hours, so vcpus * duration
    cpuhours = instance['hours']
    duration = cpuhours/instance['vcpus']
    cost = FLAVOR_COSTS.get(instance['flavor'])
    if not cost:
        cost = cost_base_hpc * instance['vcpus']
    return duration * cost

def compute_price_cinder(volume):
    if volume['volume_type'] == 'vhp':
        return volume['gbhours'] * cost_vhp_cinder
    else:
        return volume['gbhours'] * cost_base_cinder

def compute_price_swift(size, policy='replica-2'):
    if policy == 'replica-2':
        return "%d CHF" % (80*size/2**40/12)
    elif policy == 'ec104':
        return "%d CHF" % (50*size/2**40/12)
    else:
        return "N/A"

def mib_to_str(value):
    """Convert a numeric value expressed in MiB to a human-readable format"""
    if value > 2**20:
        return "%.2f TiB" % (value/2**20)
    elif value > 2**10:
        return "%.2f GiB" % (value/2**10)
    else:
        return "%.2f MiB" % value

def b_to_human(value):
    """Convert bytes to human readable string"""
    value = float(value)
    for unit, threshold in [('EiB', 2**60),
                            ('PiB', 2**50),
                            ('TiB', 2**40),
                            ('GiB', 2**30),
                            ('MiB', 2**20),
                            ('KiB', 2**10),
                            ]:
        if value > threshold:
            return "%.2f %s" % (value/threshold, unit)
    return "%d B" % value

def n_to_human(value):
    """Convert numbers using SI prefixes"""
    value = float(value)
    for unit, threshold in [('E', 10**18),
                            ('P', 10**15),
                            ('T', 10**12),
                            ('G', 10**9),
                            ('M', 10**6),
                            ('K', 10**3),]:
        if value > threshold:
            return "%.2f%s" % (value/threshold, unit)
    return "%d" % value

### Internal functions
def memoize(f):
    memo = {}
    def helper(x):
        if f not in memo:
            memo[f] = f(x)
        return memo[f]
    return helper

@memoize
def make_session(opts):
    """Create a Keystone session"""
    auth = v3.Password(auth_url=opts.os_auth_url,
                       username=opts.os_username,
                       password=opts.os_password,
                       project_name=opts.os_project_name,
                       user_domain_name=opts.os_user_domain_name,
                       project_domain_name=opts.os_project_domain_name)
    sess = session.Session(auth=auth)
    return sess

def make_new_session(opts):
    """Create a Keystone session"""
    auth = v3.Password(auth_url=opts.os_auth_url,
                       username=opts.os_username,
                       password=opts.os_password,
                       project_name=opts.os_project_name,
                       user_domain_name=opts.os_user_domain_name,
                       project_domain_name=opts.os_project_domain_name)
    sess = session.Session(auth=auth)
    return sess

def send_mail_to(smtp, mailfrom, to, subject, text, plotfiles=[]):
    msg = MIMEMultipart()
    msg['Subject'] = subject
    msg['From'] = mailfrom
    msg['To'] = to
    msg['Auto-Submitted'] = 'auto-generated'
    msg['Precedence'] = 'bulk'

    msg.attach(MIMEText(text))
    if isinstance(plotfiles, basestring):
        plotfiles = [plotfiles]
    for plotfile in plotfiles:
        if plotfile and os.path.isfile(plotfile):
            with open(plotfile, 'rb') as fd:
                part = MIMEImage(
                    fd.read(),
                    Name=os.path.basename(plotfile))
                part['Content-Disposition'] = 'attachment; filename="%s"' % os.path.basename(plotfile)
                msg.attach(part)
    log.info("Sending email to %s with subject \"%s\"", to, subject)
    s = smtplib.SMTP(smtp)
    s.sendmail(mailfrom, [to], msg.as_string())
    s.quit()
    log.info("Email successfully sent")


### Setup functions

class EnvDefault(argparse.Action):
    # This is took from
    # http://stackoverflow.com/questions/10551117/setting-options-from-environment-variables-when-using-argparse
    def __init__(self, envvar, required=True, default=None, **kwargs):
        if not default and envvar:
            if envvar in os.environ:
                default = os.environ[envvar]
        if required and default:
            required = False
        super(EnvDefault, self).__init__(default=default, required=required,
                                         **kwargs)

    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, values)

def setup():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument('--os-username',
                        action=EnvDefault,
                        envvar="OS_USERNAME",
                        help='OpenStack administrator username. If not supplied, the value of the '
                        '"OS_USERNAME" environment variable is used.')
    parser.add_argument('--os-password',
                        action=EnvDefault,
                        envvar="OS_PASSWORD",
                        help='OpenStack administrator password. If not supplied, the value of the '
                        '"OS_PASSWORD" environment variable is used.')
    parser.add_argument('--os-project-name',
                        action=EnvDefault,
                        envvar="OS_PROJECT_NAME",
                        help='OpenStack administrator project name. If not supplied, the value of the '
                        '"OS_PROJECT_NAME" environment variable is used.')
    parser.add_argument('--os-auth-url',
                        action=EnvDefault,
                        envvar="OS_AUTH_URL",
                        help='OpenStack auth url endpoint. If not supplied, the value of the '
                        '"OS_AUTH_URL" environment variable is used.')
    parser.add_argument('--os-user-domain-id',
                        action=EnvDefault,
                        envvar="OS_USER_DOMAIN_ID",
                        default='default')
    parser.add_argument('--os-project-domain-id',
                        action=EnvDefault,
                        envvar="OS_PROJECT_DOMAIN_ID",
                        default='default')
    parser.add_argument('--os-user-domain-name',
                        action=EnvDefault,
                        envvar="OS_USER_DOMAIN_NAME",
                        default='default')
    parser.add_argument('--os-project-domain-name',
                        action=EnvDefault,
                        envvar="OS_PROJECT_DOMAIN_NAME",
                        default='default')
    parser.add_argument('--send-mail',
                        action='store_true',
                        help='Send an email to contact_email and owner_email '
                        'properties of the project')
    parser.add_argument('--admin-email',
                        default="sysadmin@s3it.lists.uzh.ch",
                        help="Send full report for all the tenants to ADMIN_EMAIL. Default: %(default)s")
    parser.add_argument('--smtp',
                        default="smtp.uzh.ch",
                        help="SMTP server to use. Default: %(default)s")

    parser.add_argument('--cloud-name',
                        default='ScienceCloud',
                        help="Name of the cloud. Default: %(default)s")
    parser.add_argument('--mail-from',
                        default="sysadmin@s3it.lists.uzh.ch",
                        help="Sender Email address. Default: %(default)s")
    parser.add_argument('--start',
                        type=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'),
                        help="Create report from START date (format: YYYY-MM-DD)")
    parser.add_argument('--end',
                        type=lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'),
                        help="Create report to END date (format: YYYY-MM-DD)")
    parser.add_argument('-v', '--verbose', action='count', default=0,
                        help='Increase verbosity')
    parser.add_argument('--prices', action='store_true', help='Also include prices')
    parser.add_argument('--nova-mysql-string', required=True, help='MySQL string to access cinder database')
    parser.add_argument('--cinder-mysql-string', required=True, help='MySQL string to access cinder database')
    parser.add_argument('--swift-mysql-string', help='MySQL string to access swift accounting database')
    parser.add_argument('--plots', action='store_true', help='Attach a plot with the usage')
    parser.add_argument('--yesterday', action='store_true', help='Get reports from yesterda')
    parser.add_argument('-p', '--parallel', default=4, type=int)
    parser.add_argument('--datadir', default='/tmp/sc-send-report', help='Directory where csv data')
    parser.add_argument('--report-mysql-string', help='MySQL string to save reports into a MySQL database')
    parser.add_argument('--services', default="nova,swift,cinder", help='Comma separated list of services we want to check')
    parser.add_argument('project',
                        nargs='*',
                        help="Create reports only for these projects. Default: all projects")

    opts = parser.parse_args()
    if not PLOT_ENABLED:
        log.warning("Option --plots disabled as some modules are missing. Ensure you have installed the modules 'pandas' and 'matplotlib'")
        opts.plots = False
    # Set verbosity
    verbosity = max(0, 3-opts.verbose) * 10
    log.setLevel(verbosity)
    # if not opts.start or not opts.end:
    #     pass # not yet implemented
    if opts.yesterday:
        now = datetime.datetime.now()
        y_now = now - datetime.timedelta(days=1)
        opts.start = datetime.datetime(y_now.year, y_now.month, y_now.day, 0, 0)
        opts.end = opts.start + datetime.timedelta(days=1)
    elif (opts.start and not opts.end) or \
       (not opts.start and opts.end):
        parser.error("You either specify both --start and --end, or you just use the default")
    elif not opts.start:
        now = datetime.datetime.now()
        # get to the first day of the month
        firstday=datetime.datetime(now.year, now.month, 1, 0, 0)
        # Go back 24 hours and one minute
        opts.end = firstday - datetime.timedelta(hours=24,minutes=1)
        # Go back at the first day of last month
        opts.start = datetime.datetime(opts.end.year, opts.end.month, 1, 0, 0)
    else:
        # opts.end should be the whole day
        opts.end = datetime.datetime(opts.end.year, opts.end.month, opts.end.day, 23, 59)

    return opts

### OpenStack functions

class CinderChecker(mp.Process):
    def __init__(self, tasks, results, opts):
        mp.Process.__init__(self)
        self.tasks = tasks
        self.results = results
        self.opts = opts
        self.cclient = None
        self.connect()

    def connect(self):
        if self.cclient:
            return self.cclient
        try:
            sess = make_new_session(self.opts)
            self.cclient = cinder_client.Client('2', session=sess)
            self.volume_types = self.cclient.volume_types.list()
            return self.cclient
        except:
            return False

    def run(self):
        for i in range(10):
            if self.connect():
                break
            time.sleep(5)
        while True:
            try:
                project = self.tasks.get_nowait()
            except:
                break
            if project is None:
                log.debug("CinderChecker %s: Queue is empty, exiting", self.name)
                break
            report = self.get_cinder_stats(project)
            report['project'] = project
            self.results.put(report)
            self.tasks.task_done()

    def get_cinder_stats(self, project):
        log.info("Checking cinder for project %s", project['name'])
        quota = self.cclient.quotas.get(project['id'], usage=True)
        report =  {'usage': {'': {'volumes': quota.volumes,
                                  'gigabytes': quota.gigabytes}}}
        for vol in self.volume_types:
            if hasattr(quota, 'volumes_%s' % vol.name) and \
               hasattr(quota, 'gigabytes_%s' % vol.name):
                report['usage'][vol.name] = {'volumes': getattr(quota, 'volumes_%s' % vol.name),
                                    'gigabytes': getattr(quota, 'gigabytes_%s' % vol.name)}
        log.debug("CINDER report for project %s: %s", project['name'], report)
        return report

def get_cinder_summary(opts, projects, sess=None):
    if not sess:
        sess = make_sessions(opts)
    reports = []
    tasks = mp.JoinableQueue()
    results = mp.Queue()
    for project in projects:
        p = project.to_dict()
        tasks.put(p)
    if len(projects) != tasks.qsize():
        log.error("Task queue is %d but we have %d projects", tasks.qsize(), len(projects))

    consumers = [CinderChecker(tasks, results, opts) for i in range(opts.parallel)]
    for w in consumers:
        w.start()
    tasks.join()
    if len(projects) != results.qsize():
        log.error("Result task queue is %d but we have %d tasks", results.qsize(), len(projects))

    for i in range(results.qsize()):
        reports.append(results.get())

    return {r['project']['id']:r for r in reports}

def get_cinder_detailed(opts):
    # Access MySQL database to get a list of volumes that were up&running during this time.
    db = sqla.create_engine(opts.cinder_mysql_string, echo=False)
    metadata = sqla.MetaData(bind=db)
    metadata.reflect()
    volumes = metadata.tables['volumes']
    volume_types = metadata.tables['volume_types']
    q = sql.select([
        volumes.c.project_id,     # 0
        volumes.c.id,             # 1
        volumes.c.display_name,   # 2
        volumes.c.volume_type_id, # 3
        volumes.c.size,           # 4
        sqla.func.greatest(volumes.c.created_at, str(opts.start)).label('start'), # 5
        sqla.func.least(volumes.c.deleted_at, str(opts.end)).label('end'), # 6
        volumes.c.created_at, # 7
        volumes.c.deleted_at, # 8
        volume_types.c.name.label('volume_type_name'),
    ]).select_from(volumes.join(volume_types, volumes.c.volume_type_id==volume_types.c.id)).where(
        sql.not_(
            sql.or_(
                volumes.c.created_at > str(opts.end),
                sql.and_(
                    sql.not_(volumes.c.deleted_at==sql.null()),
                    volumes.c.deleted_at< str(opts.start))
            )
        )
    )
    results = db.execute(q)

    # Fix deleted_at, which might be NULL on MySQL. In this case, we will select the smaller value.
    rows = defaultdict(list)

    for row in results.fetchall():
        end = row['end'] if row['end'] else str(opts.end)
        currow = {
            'project_id': row['project_id'],
            'id': row['id'],
            'name': row['display_name'],
            'volume_type': row['volume_type_name'],
            'size': row['size'],
            'start': datetime.datetime.strptime(row['start'], '%Y-%m-%d %H:%M:%S'),
            'end': datetime.datetime.strptime(end, '%Y-%m-%d %H:%M:%S'),
        }
        currow['gbhours'] = currow['size']*(currow['end'] - currow['start']).total_seconds()/60/60
        rows[currow['project_id']].append(currow)
    return rows


def get_nova_detailed(opts):
    db = sqla.create_engine(opts.nova_mysql_string, echo=False)
    metadata = sqla.MetaData(bind=db)
    metadata.reflect()
    instances = metadata.tables['instances']
    flavors = metadata.tables['instance_types']
    q = sql.select([
        instances.c.uuid.label('instance_id'),
        instances.c.display_name.label('name'),
        instances.c.user_id,
        instances.c.project_id,
        instances.c.vcpus,
        instances.c.memory_mb,
        sqla.func.greatest(instances.c.launched_at, instances.c.created_at).label('started_at'),
        sqla.func.least(instances.c.terminated_at, instances.c.deleted_at).label('ended_at'),
        flavors.c.name.label('flavor'),
        sqla.func.greatest(instances.c.created_at, str(opts.start)).label('start'), # 5
        sqla.func.least(instances.c.deleted_at, str(opts.end)).label('end'), # 6
    ]).select_from(
        instances.join(flavors, instances.c.instance_type_id==flavors.c.id)
    ).where(
        sql.not_(
            sql.or_(
                instances.c.created_at > str(opts.end),
                sql.and_(
                    sql.not_(instances.c.deleted_at==sql.null()),
                    instances.c.deleted_at< str(opts.start))
            )
        )
    )
    results = q.execute()
    instances = defaultdict(NovaSummary)
    total_vcpus_usage = 0
    total_memory_mb_usage = 0

    for row in results.fetchall():
        end = row['end'] if row['end'] else str(opts.end)
        currow = {
            'project_id': row['project_id'],
            'tenant_id': row['project_id'],
            'instance_id': row['instance_id'],
            'name': row['name'],
            'flavor': row['flavor'],
            'vcpus': row['vcpus'],
            'memory_mb': row['memory_mb'],
            'start': datetime.datetime.strptime(row['start'], '%Y-%m-%d %H:%M:%S'),
            'end': datetime.datetime.strptime(end, '%Y-%m-%d %H:%M:%S'),
            'started_at': row['started_at'],
            'ended_at': row['ended_at'],
        }
        currow['hours'] = currow['vcpus']*(currow['end'] - currow['start']).total_seconds()/60/60
        instances[currow['project_id']].append(currow)

    return instances

class SwiftChecker(mp.Process):
    def __init__(self, tasks, results, opts):
        mp.Process.__init__(self)
        self.tasks = tasks
        self.results = results
        self.opts = opts

    def run(self):
        while True:
            try:
                project = self.tasks.get_nowait()
            except:
                break
            if project is None:
                log.debug("SwiftChecker %s: Queue is empty, exiting", self.name)
                break
            report = self.get_swift_stats(project)
            report['project'] = project
            self.results.put(report)
            self.tasks.task_done()

    def get_swift_stats(self, project):
        log.debug("Checking swift for project %s", project['name'])
        conn = swiftclient.Connection(
            authurl=self.opts.os_auth_url,
            user=self.opts.os_username,
            key=self.opts.os_password,
            os_options={"auth_url": self.opts.os_auth_url,
                        "project_name": self.opts.os_project_name,
                        "project_domain_name": self.opts.os_project_domain_name,
                        "username": self.opts.os_username,
                        "user_domain_name": self.opts.os_user_domain_name,
                        "password": self.opts.os_password,
                        "object_storage_url": project['storage_url'],},
            auth_version='3')
        account,containers = conn.get_account()
        acc_report = {
            'bytes': int(account['x-account-bytes-used']),
            'containers': int(account.get('x-account-container-count', 0)),
            'objects': int(account.get('x-account-object-count', 0)),
            'quota': int(account.get('x-account-meta-quota-bytes', -1)),
        }
        policies = acc_report['policies'] = defaultdict(dict)
        # Check per-storage policy data
        for key, value in account.items():
            m = respolicy.search(key)
            if m:
                policies[m.group('policy')][m.group('value')] = int(value)

        log.debug("REPORT for project: %s: %s", project['name'], acc_report)
        return acc_report

def get_swift_summary_live(opts, projects, sess=None):
    reports = {}
    tasks = mp.JoinableQueue()
    results = mp.Queue()
    projects = projects.values()
    # get endpoint
    if not sess:
        sess = make_session(opts)
    keystone = keystone_client.Client(session=sess)
    try:
        swift_service = keystone.services.find(type='object-store')
    except:
        raise Exception("Unable to find service swift")

    try:
        swift_endpoint = keystone.endpoints.find(interface='public',
                                                 service_id=swift_service.id)
    except:
        raise Exception("No endpoint defined for service swift")

    for project in projects:
        p = project.to_dict()
        p['storage_url'] = swift_endpoint.url % {'tenant_id':project.id}
        tasks.put(p)

    if len(projects) != tasks.qsize():
        log.error("Task queue is %d but we have %d projects", tasks.qsize(), len(projects))
    consumers = [SwiftChecker(tasks, results, opts) for i in range(opts.parallel)]
    for w in consumers:
        w.start()

    log.debug("Joining task queue")
    tasks.join()
    if len(projects) != results.qsize():
        log.error("Result task queue is %d but we have %d tasks", results.qsize(), len(projects))
    log.info("Terminating consumers")
    # [w.terminate() for w in consumers]
    reports = []
    for i in range(results.qsize()):
    # while not results.empty():
        reports.append(results.get())
    return {r['project']['id']:r for r in reports}

def get_swift_summary(opts, projects, sess=None):
    db = sqla.create_engine(opts.swift_mysql_string, echo=False)
    metadata = sqla.MetaData(bind=db)
    metadata.reflect()
    swift = metadata.tables['swift_accounting']
    q = sql.select([swift.c.project_id,
                    swift.c.project_name,
                    swift.c.policy,
                    swift.c.containers,
                    swift.c.objects,
                    swift.c.size_b,
                    swift.c.last_seen,
                    swift.c.timestamp,
    ])

    if not projects:
        q = q.where(sql.and_(swift.c.timestamp>=opts.start,
                             swift.c.timestamp<=opts.end))
    else:
        cond = [swift.c.timestamp>=opts.start,
                swift.c.timestamp<=opts.end] + [swift.c.project_id==p.id for p in projects]
        q = q.where(sql.and_(*cond))

    q = q.order_by(swift.c.timestamp)
    results = q.execute()

    report = defaultdict(list)
    for row in results.fetchall():
        drow = dict(row)
        report[drow['project_id']].append(drow)

    return report

### Reporting functions

def create_nova_report(project, nova_summary, instances, opts):
    report = []
    csvdata = []
    csvdata_detailed = []
    total_price = 0

    # Detailed information
    header_detailed = [
        'instance UUID',
        'instance name',
        'flavor',
        'vcpus',
        'cpu hours',
    ]
    if opts.prices:
        header_detailed.append('Cost')
    csvdata_detailed.append(header_detailed + ['started_at', 'ended_at', 'memory_mb'])
    pt_det = prettytable.PrettyTable(header_detailed, print_empty=False)
    pt_det.align['instance name'] = 'l'
    pt_det.align['flavor'] = 'l'
    pt_det.align['vcpus'] = 'r'
    pt_det.align['cpu hours'] = 'r'
    if opts.prices:
        pt_det.align['Cost'] = 'r'

    for uuid, instance in instances.items():
        cpuhours = instance['hours']
        row = [uuid,
               instance['name'],
               instance['flavor'],
               instance['vcpus'],
               "%.2f hours" % cpuhours,
        ]
        if opts.prices:
            price = compute_price_nova(instance)
            total_price += price
            row.append("%.4f CHF" % price)

        pt_det.add_row(row)
        row += [instance['started_at'],
                instance['ended_at'],
                instance['memory_mb'],
        ]
        csvdata_detailed.append(row)

    # Finally, add to the report

    # Summary information
    header = ['vcpu hours', 'ram (hours)']
    if opts.prices:
        header.append("Cost")

    pt = prettytable.PrettyTable(header)
    pt.align['vcpu hours'] = 'r'
    pt.align['ram (hours)'] = 'r'
    if opts.prices:
        pt.align['Cost'] = 'r'

    row = ["%.2f" % nova_summary.total_vcpus_usage,
           # "%.2f" % (cpu[project].max/1e+9/60/60),
           mib_to_str(nova_summary.total_memory_mb_usage),
    ]
    if opts.prices:
        row.append("%.2f CHF" % total_price)
    csvdata = [header, row]
    pt.add_row(row)
    report.append("Summary of usage for project %s\n" % project.name)
    report.append(str(pt))

    table = str(pt_det)
    if table:
        report.append("")
        report.append("Detailed usage for project %s - instances\n" % project.name)
        report.append(str(table))

    # We might generate a plot here
    plotfile = ''
    if opts.plots:
        df = pd.DataFrame.from_dict(instances, orient='index')
        df.started_at = pd.to_datetime(df.started_at)
        df.ended_at = pd.to_datetime(df.ended_at)

        vms_by_day = []

        for t in pd.date_range(opts.start, opts.end):
            d = df[~((df.ended_at < t) | (df.started_at > t))]
            vms_by_day.append((t, d.instance_id.count(), d.vcpus.sum()))
        ts = pd.DataFrame(vms_by_day, columns=['date','VMs','vcpus'])
        ts.index = ts.date

        with plt.xkcd():
            # because we are not serious people...
            fig = plt.figure()

            plt.plot(ts['VMs'])
            plt.plot(ts['vcpus'])
            plt.legend(loc=0)

            # Annotate the busiest day
            xmax = ts['vcpus'].idxmax()

            # X coordinate of the text will never go beyond 1/4 of the x width
            timespan = ts.index.max()-ts.index.min()
            max_x_text = ts.index.max() - datetime.timedelta(days=(timespan/4).days)
            # Ensure the X of the text is between the beginning of the
            # plot and max_x_text, but try to move it a bit to the
            # left
            xtext = min(max(xmax-datetime.timedelta(days=2), ts.index.min()), max_x_text)
            ymax = ts.ix[xmax]['vcpus']
            plt.annotate('Busiest day (%d)' % ymax, xy=(xmax,ymax), arrowprops=dict(arrowstyle='->'), xytext=(xtext, ymax-ymax/10.0))

            # Format dates so that they do not overlap
            fig.autofmt_xdate()

            # Set title
            fig.axes[0].set_title("VMs and vCPUs usage for project %s\nfrom %s to %s" % (
                project.name, opts.start, opts.end))
            ylim = plt.ylim()
            plt.ylim((ylim[0]-ts.vcpus.min(), ylim[1]+ts.vcpus.min()))
            # Save to file
            plotfile = os.path.join(opts.datadir, 'nova_plot_%s-%s_%s.png' % (
                opts.start.strftime('%Y-%m-%d'), opts.end.strftime('%Y-%m-%d'), project.name))
            plt.savefig(plotfile)
            plt.clf()
            plt.close('all')

    return (str.join('\n', report), {'summary': csvdata, 'detailed': csvdata_detailed, 'plot': plotfile})


def create_cinder_report(project, cinder_summary, cinder_detailed):
    report = []
    csvdata = []
    total_price = defaultdict(int)

    if cinder_detailed:
        header = ['id', 'name', 'Size (GiB)', 'GiB hours']
        if opts.prices:
            header.append("Cost")

        pt_det = prettytable.PrettyTable(header, print_empty=False)
        pt_det.align['name'] = 'l'
        pt_det.align['Size (GiB)'] = 'r'
        pt_det.align['GiB hours'] = 'r'
        if opts.prices:
            pt_det.align['Cost'] = 'r'

        for voldata in cinder_detailed:
            row = [voldata['id'], voldata['name'], voldata['size'], "%.2f" % voldata['gbhours']]
            if opts.prices:
                voldata['cost'] = compute_price_cinder(voldata)
                total_price[voldata['volume_type']] += voldata['cost']
                row.append('%.3f CHF' % voldata['cost'])
            pt_det.add_row(row)

        # Also make the plot
        plotfile = ''
        vol_by_day = []

        df = pd.DataFrame(cinder_detailed)
        df.start = pd.to_datetime(df.start)
        df.end = pd.to_datetime(df.end)
        csvdata_detailed = [list(df.columns)]
        csvdata_detailed += df.values.tolist()
        for t in pd.date_range(opts.start, opts.end):
            d = df[~((df.end < t) | (df.start > t))]
            vol_by_day.append((t, d['id'].count(), d['size'].sum()))

        ts = pd.DataFrame(vol_by_day, columns=['date', 'volumes', 'GiB used'])
        ts.index = ts.date

        if opts.plots:
            with plt.xkcd():
                # because we are not serious people...
                fig, ax = plt.subplots()
                axes = [ax, ax.twinx()]
                p1 = axes[0].plot(ts['volumes'], 'b-')
                p2 = axes[1].plot(ts['GiB used'], 'r-')
                # because we are not serious people...
                # fig = plt.figure()
                # ax1 = fig.add_subplot(111)
                # ax1.plot(ts['volumes'])
                # ax1.set_ylabel('volumes')
                axes[0].set_ylim(0, ts['volumes'].max()+1)
                axes[1].set_ylim(0, ts['GiB used'].max()*1.2)
                # ax2 = fig.add_subplot(111, sharex=ax1)
                # ax2.plot(ts['GiB used'])
                # ax2.yaxis.tick_right()
                # ax2.set_ylim(0, ts['GiB used'].max()+10)
                # ax2.yaxis.set_label_position("right")
                axes[0].set_ylabel('volumes')
                axes[1].set_ylabel('gigabytes')

                plt.legend((p1[0], p2[0]), (p1[0].get_label(), p2[0].get_label()), loc=0)
                fig.autofmt_xdate()
                # Set title
                ax.set_title("Cinder volumes and used space for project %s\nfrom %s to %s" % (
                    project.name, opts.start, opts.end))

                # Save to file
                plotfile = os.path.join(opts.datadir, 'cinder_plot_%s-%s_%s.png' % (
                    opts.start.strftime('%Y-%m-%d'), opts.end.strftime('%Y-%m-%d'), project.name))
                plt.savefig(plotfile)
                plt.clf()
                plt.close('all')

    # Summary data
    header = ['volume type', 'volumes', 'quota usage (volumes)', 'gigabytes', 'quota usage (gigabytes)']
    if opts.prices:
        header.append('Cost')
    csvdata.append(header)
    pt = prettytable.PrettyTable(header, print_empty=False)
    for field in pt.field_names:
        pt.align[field] = 'r'
    pt.align['volume type'] = 'l'
    if opts.prices:
        pt.align['Cost'] = 'r'

    global_quota = cinder_summary['usage']['']
    for voltype, quota in cinder_summary['usage'].items():
        if voltype == '':
            continue
        volumes = quota['volumes']
        if volumes['in_use'] == 0: continue
        gigabytes = quota['gigabytes']
        vol_limit = volumes['limit'] if volumes['limit'] != -1 else global_quota['volumes']['limit']
        gb_limit = gigabytes['limit'] if gigabytes['limit'] != -1 else global_quota['gigabytes']['limit']
        row = [voltype,
               "%d" % volumes['in_use'],
               "%.2f %%" % abs(volumes['in_use']*100.0/vol_limit),
               "%d" % gigabytes['in_use'],
               "%.2f %%" % abs(gigabytes['in_use']*100.0/gb_limit),
        ]
        if opts.prices:
            row.append('%.2f CHF' % total_price.get(voltype, -1))
        csvdata.append(row)
        pt.add_row(row)
    table = str(pt)
    if table:
        report.append("Summary of block storage usage for project %s" % project.name)
        if opts.prices:
            report.append("(Cost of block storage is based on detailed report)")
        report.append('')
        report.append(str(pt))
    else:
        report.append("No Cinder volumes used")

    if cinder_detailed:
        report.append('')
        report.append("Detailed usage for project %s - volumes" % project.name)
        report.append('')
        report.append(str(pt_det))

    reportdata = {'summary': csvdata}
    if cinder_detailed:
        reportdata['detailed'] = csvdata_detailed
        reportdata['plot'] = plotfile
    return (str.join('\n', report), reportdata)

def create_swift_report(project, swift_summary):
    report = []
    df = pd.DataFrame(swift_summary)
    if not len(df):
        # No data
        return ("No SWIFT storage used", {})

    # This is a timeseries of the swift usage.
    # We get the average and the current usage
    current = df.groupby('policy', as_index=False).last()

    pt = prettytable.PrettyTable(['Storage Policy', 'objects', 'containers', 'bytes', 'size'])
    pt.align['Storage Policy'] = 'l'
    pt.align['objects'] = 'r'
    pt.align['containers'] = 'r'
    pt.align['bytes'] = 'r'
    pt.align['size'] = 'r'

    for policy, values in current.iterrows():
        pt.add_row([policy,
                    values.objects,
                    values.containers,
                    values.size_b,
                    b_to_human(values.size_b)])
    report.append("Summary of SWIFT storage for project %s\n" % project.name)
    report.append(str(pt))

    # Plot data
    plotfile = ''
    if opts.plots:
        df.index = df.timestamp

        df['GiB'] = df.size_b/2.0**30
        df['TiB'] = df.size_b/2.0**40
        col = 'TiB' if df['TiB'].max() > 1 else 'GiB'
        with plt.xkcd():
            # because we are not serious people...
            fig = plt.figure()
            for policy in df.policy.unique():
                tspol = df[df.policy==policy]
                plt.plot(tspol[col], label='%s (%s)' % (policy, col))
            plt.legend(loc=0)

            fig.autofmt_xdate()
            fig.axes[0].set_title("SWIFT Space used in %s\nfrom %s to %s" % (col, opts.start, opts.end))

            plotfile = os.path.join(opts.datadir, 'swift_plot_%s-%s_%s.png' % (
                opts.start.strftime('%Y-%m-%d'), opts.end.strftime('%Y-%m-%d'), project.name))
            plt.savefig(plotfile)
            plt.clf()
            plt.close('all')

    reportdata = {
        'summary': [current.columns.tolist()] + current.values.tolist(),
        'detailed': [df.columns.tolist()] + df.values.tolist(),
        'plot': plotfile,
    }
    return (str.join('\n', report), reportdata)


def create_swift_report_old(project, swift_summary):
    if not swift_summary or (swift_summary['objects'] ==  swift_summary['containers'] == 0):
        return ("No SWIFT storage used", {})

    report = []
    header = ['objects', 'containers', 'bytes']
    csvdata = [header]
    pt = prettytable.PrettyTable(header)
    for k in pt.align:
        pt.align[k] = 'r'

    row = ["%d (%s)" % (swift_summary['objects'], n_to_human(swift_summary['objects'])),
           "%d (%s)" % (swift_summary['containers'], n_to_human(swift_summary['containers'])),
           "%d (%s)" % (swift_summary['bytes'], b_to_human(swift_summary['bytes'])),
    ]
    pt.add_row(row)
    csvdata.append([
        swift_summary['objects'],
        swift_summary['containers'],
        swift_summary['bytes'],
    ])
    report.append("Summary of SWIFT storage for project %s\n" % project.name)
    report.append(str(pt))

    csvdata_detailed = []
    if swift_summary['policies'] > 0:
        header = ['Storage policy', 'bytes', 'objects']
        csvdata_detailed.append(header)
        pt = prettytable.PrettyTable(header)
        # pt = prettytable.PrettyTable(('Storage policy', 'bytes', 'objects', 'quota price', 'actual price'))
        pt.align['Storage policy'] = 'l'
        pt.align['bytes'] = 'r'
        pt.align['objects'] = 'r'
        # pt.align['quota price'] = 'r'
        # pt.align['actual price'] = 'r'
        for policy, data in swift_summary['policies'].items():
            row = [policy,
                   "%d (%s)" % (data['bytes-used'], b_to_human(data['bytes-used'])),
                   "%d (%s)" % (data['object-count'], n_to_human(data['object-count'])),
                   # compute_price_swift(swift_summary['quota']),
                   # compute_price_swift(data['bytes-used'], policy),
            ]
            pt.add_row(row)
            csvdata_detailed.append([policy, data['bytes-used'], data['object-count']])
        report.append("")
        report.append("Summary of SWIFT storage by storage policy for project %s\n" % project.name)
        report.append(str(pt))

    reportdata = {'summary': csvdata}
    if csvdata_detailed:
        reportdata['detailed'] = csvdata_detailed
    return (str.join('\n', report), reportdata)


def main(opts):
    sess = make_session(opts)
    keystone = keystone_client.Client(session=sess)

    services = [i for i in ['nova', 'cinder', 'swift'] if i in opts.services.split(',')]

    # Get the projects
    all_projects = keystone.projects.list(enabled=True)
    if opts.project:
        projects = {p.id: p for p in all_projects  if p.name in opts.project or p.id in opts.project}
    else:
        projects = {p.id:p for p in all_projects}

    log.debug("Projects to analyze: %s" , str.join(', ', [p.name for p in projects.values()]))

    if 'swift' in services:
        # Get usage from swift
        swift_summary = get_swift_summary(opts, projects.values() if opts.project else [])

    if 'cinder' in services:
        # Get summary from cinder
        cinder_summary = get_cinder_summary(opts, projects.values(), sess=sess)
        cinder_detailed = get_cinder_detailed(opts)

    if 'nova' in services:
        # Get usage from nova
        instances = {}
        summary = get_nova_detailed(opts)
        for report in summary.values():
            instances.update({i['instance_id']: i for i in report.server_usages})

        log.debug("Got detailed information for %s instances" % len(instances))


    # For each project, get the report.
    # all_reports is used to send a single report with all information to the ADMIN_RECIPIENT
    all_reports = {}
    for project in projects.values():
        all_reports[project.id] = {'nova':{}, 'cinder':{}, 'swift':{}}
        streport = ''
        # Get cinder reports
        if 'cinder' in services:
            try:
                creport, cdata = create_cinder_report(project, cinder_summary[project.id], cinder_detailed[project.id])
                streport += creport

                all_reports[project.id]['cinder'] = cdata
            except Exception as ex:
                log.warn("Error while generating CINDER report for project %s: %s", project.name, ex)

        if 'nova' in services:
            # get nova report
            try:
                if project.id in summary:
                    nreport, ndata = create_nova_report(project, summary[project.id], dict([(k,v) for k,v in instances.items() if v['tenant_id'] == project.id]), opts)
                    all_reports[project.id]['nova'] = ndata
                    streport += '\n\n%s' % nreport

            except Exception as ex:
                log.warn("Error while generating NOVA report for project %s: %s", project.name, ex)

        if 'swift' in services:
            # get swift report
            try:
                sreport, sdata = create_swift_report(project, swift_summary.get(project.id))
                all_reports[project.id]['swift'] = sdata
                streport += '\n\n%s' % sreport
            except Exception as ex:
                log.warn("Error while generating SWIFT report for project %s: %s", project.name, ex)

        all_reports[project.id]['msg'] = streport

    # Save data
    for service in services:
        for reportype in ['summary', 'detailed']:
            if not [i for i in all_reports.values() if reportype in i[service]]:
                # No `reportype` report for this service: skip it
                continue
            fname = os.path.join(opts.datadir, "%s-%s_%s-%s.csv" % (
                service, reportype, opts.start.strftime('%Y-%m-%d'), opts.end.strftime('%Y-%m-%d')))
            write_header = True
            try:
                if not os.path.isdir(os.path.dirname(fname)):
                    os.makedirs(os.path.dirname(fname))
                with open(fname, 'w') as fd:
                    writer = csv.writer(fd)
                    for project_id, report in all_reports.items():
                        # Again, check if for some projects maybe there is no report
                        pname = projects.get(project_id).name
                        if not report[service] or reportype not in  report[service]:
                            log.info("Skipping project %s as no '%s' report is found for service %s",
                                     project_id, reportype, service)
                            continue
                        if write_header:
                            writer.writerow(['Project'] + report[service][reportype][0])
                            write_header = False
                        for row in report[service][reportype][1:]:
                            writer.writerow([pname] + row)
            except Exception as ex:
                log.error("Exception while opening file %s: %s", fname, ex)
    # Send emails, if requested
    if opts.send_mail:
        try:
            plotfiles = []
            for report in all_reports.values():
                for service in ('nova', 'cinder'):
                    if service in report and report[service].get('plot'):
                        plotfiles.append(report[service].get('plot'))
            send_mail_to(opts.smtp,
                         opts.mail_from,
                         opts.admin_email,
                         "%s usage from %s to %s" % (opts.cloud_name, opts.start, opts.end),
                         str.join("\n\n", [r['msg'] for r in all_reports.values()]),
                         plotfiles,
            )
        except Exception as ex:
            log.error("Unable to send email to admin %s: %s",
                      opts.admin_email, ex)
        for project_id, report in all_reports.items():
            try:
                pdict = projects.get(project_id).to_dict()
                if pdict.get('report_recipients'):
                    recipients = set(pdict.get('report_recipients').split(','))
                else:
                    recipients = set([pdict.get('contact_email'),
                                      pdict.get('owner_email'),
                                      pdict.get('s3it_owner_email')])
            except Exception as ex:
                log.error("Error getting recipients address from project id %s" % project_id)
                continue
            for recipient in recipients:
                if recipient:
                    try:
                        plotfiles = []
                        for service in ('nova', 'cinder', 'swift'):
                            if service in report and report[service].get('plot'):
                                plotfiles.append(report[service].get('plot'))
                        send_mail_to(opts.smtp,
                                     opts.mail_from,
                                     recipient,
                                     "%s usage for project %s from %s to %s" % (opts.cloud_name, pdict['name'], opts.start, opts.end),
                                     report['msg'],
                                     plotfiles)
                    except Exception as ex:
                        log.error(
                            "Unable to send report email for project %s to"
                            " recipient %s: %s", pdict['name'], recipient, ex)
    else:
        print("Reports from %s to %s" % (opts.start, opts.end))
        for project_id, report in all_reports.items():
            print("="*80)
            print(report['msg'])
            print("")

if __name__ == "__main__":
    opts = setup()
    if not os.path.exists(opts.datadir):
        os.makedirs(opts.datadir)
    sys.exit(main(opts))
